# -*- coding: utf-8 -*-
"""Design Project New.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sr0ITOQNMz0x0dPuGPtl9TxnWCYrngpT
"""

!pip install mplfinance pandas

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your actual CSV file path
output_folder = 'candlestick_images'  # Folder to save candlestick images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Generate candlestick images for each day in stock data
    for _, row in stock_data.iterrows():
        date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']

        # Initialize a figure and axis
        fig, ax = plt.subplots(figsize=(2, 4))  # Aspect ratio for candlestick chart
        color = 'green' if close_price >= open_price else 'red'  # Green for bullish, red for bearish

        # Plot candlestick body
        ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

        # Plot high and low wicks
        ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

        # Adjust plot aesthetics
        ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
        ax.set_ylim(low_price - (0.05 * low_price), high_price + (0.05 * high_price))
        ax.axis('off')  # Hide axes

        # Save the figure
        image_path = os.path.join(output_folder, f"{date.strftime('%Y-%m-%d')}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.1)
        plt.close(fig)  # Close the figure to free memory

    print(f"Candlestick images successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Update this path to your actual CSV file path
output_folder = 'monthly_candlestick_charts'  # Folder to save monthly candlestick images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Extract the year and month from the date for grouping
    stock_data['YearMonth'] = stock_data['Date'].dt.to_period('M')

    # Group data by YearMonth
    grouped_data = stock_data.groupby('YearMonth')

    # Generate a candlestick chart for each month
    for year_month, group in grouped_data:
        fig, ax = plt.subplots(figsize=(10, 6))  # Larger figure for monthly chart
        group = group.sort_values('Date')  # Ensure data is sorted by date

        for _, row in group.iterrows():
            date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']
            color = 'green' if close_price >= open_price else 'red'  # Green for bullish, red for bearish

            # Plot candlestick body
            ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.6)

            # Plot high and low wicks
            ax.vlines(date, low_price, high_price, color='black', linewidth=0.8)

        # Adjust plot aesthetics
        ax.set_title(f"Candlestick Chart for {year_month}", fontsize=16)
        ax.set_xlabel('Date', fontsize=12)
        ax.set_ylabel('Price', fontsize=12)
        ax.grid(True)
        fig.autofmt_xdate()  # Automatically format x-axis dates

        # Save the figure
        image_path = os.path.join(output_folder, f"{year_month}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.1)
        plt.close(fig)  # Close the figure to free memory

    print(f"Monthly candlestick charts successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from statsmodels.tsa.arima.model import ARIMA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# Load the stock data
stock_data = pd.read_csv('ADANIPORTS.csv')

# Preview the data
print("Stock Data Preview:")
print(stock_data.head())

# Ensure the Date column is parsed as datetime and sorted
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data.sort_values(by='Date', inplace=True)

# Set the 'Close' price as the target variable (modify if needed)
target_column = 'Close'
data = stock_data[['Date', target_column]].dropna()

# Normalize data for models that require scaling (e.g., LSTM, SVM)
scaler = MinMaxScaler()
data['Scaled_Close'] = scaler.fit_transform(data[[target_column]])

# Split the data into training and testing sets
train_size = int(len(data) * 0.8)
train, test = data[:train_size], data[train_size:]

# Prepare features for supervised models
X_train, y_train = train.index.values.reshape(-1, 1), train[target_column].values
X_test, y_test = test.index.values.reshape(-1, 1), test[target_column].values

# Prepare LSTM data (sequential input-output)
def create_lstm_dataset(data, look_back=1):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:i + look_back, 0])
        y.append(data[i + look_back, 0])
    return np.array(X), np.array(y)

look_back = 10
lstm_data = scaler.fit_transform(data[[target_column]].values)
X_lstm, y_lstm = create_lstm_dataset(lstm_data, look_back)
X_lstm_train, X_lstm_test = X_lstm[:train_size], X_lstm[train_size - look_back:]
y_lstm_train, y_lstm_test = y_lstm[:train_size], y_lstm[train_size - look_back:]

# Reshape LSTM input to [samples, time steps, features]
X_lstm_train = np.reshape(X_lstm_train, (X_lstm_train.shape[0], X_lstm_train.shape[1], 1))
X_lstm_test = np.reshape(X_lstm_test, (X_lstm_test.shape[0], X_lstm_test.shape[1], 1))

# Train ARIMA model
arima_model = ARIMA(train[target_column], order=(5, 1, 0))
arima_result = arima_model.fit()
arima_forecast = arima_result.forecast(steps=len(test))

# Train Random Forest model
rf_model = RandomForestRegressor()
rf_model.fit(X_train, y_train)
rf_predictions = rf_model.predict(X_test)

# Train SVM model
svm_model = SVR()
svm_model.fit(X_train, y_train)
svm_predictions = svm_model.predict(X_test)

# Train Regression model
reg_model = LinearRegression()
reg_model.fit(X_train, y_train)
reg_predictions = reg_model.predict(X_test)

# Train LSTM model
lstm_model = Sequential([
    LSTM(50, input_shape=(look_back, 1), return_sequences=True),
    LSTM(50),
    Dense(1)
])
lstm_model.compile(optimizer='adam', loss='mean_squared_error')
lstm_model.fit(X_lstm_train, y_lstm_train, epochs=10, batch_size=32, verbose=1)
lstm_predictions = lstm_model.predict(X_lstm_test)
lstm_predictions = scaler.inverse_transform(lstm_predictions)

# Evaluate models
def evaluate_model(name, y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f"\n{name} Evaluation:")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RÂ²: {r2:.4f}")

evaluate_model("ARIMA", y_test, arima_forecast)
evaluate_model("Random Forest", y_test, rf_predictions)
evaluate_model("SVM", y_test, svm_predictions)
evaluate_model("Regression", y_test, reg_predictions)
evaluate_model("LSTM", y_test, lstm_predictions[:, 0])

# Plot predictions
plt.figure(figsize=(15, 8))
plt.plot(test['Date'], y_test, label='Actual', color='black')
plt.plot(test['Date'], arima_forecast, label='ARIMA', color='blue')
plt.plot(test['Date'], rf_predictions, label='Random Forest', color='green')
plt.plot(test['Date'], svm_predictions, label='SVM', color='orange')
plt.plot(test['Date'], reg_predictions, label='Regression', color='purple')
plt.plot(test['Date'], lstm_predictions, label='LSTM', color='red')
plt.legend()
plt.title("Stock Price Predictions")
plt.xlabel("Date")
plt.ylabel("Price")
plt.show()

import matplotlib.pyplot as plt
import os
from PIL import Image

# Define the folder containing the monthly candlestick charts
output_folder = 'monthly_candlestick_charts'

# Get a list of all image files in the folder
image_files = [file for file in os.listdir(output_folder) if file.endswith('.png')]

# Sort the images by name (to maintain chronological order if filenames are YearMonth)
image_files.sort()

# Display the images in a grid
n_cols = 3  # Number of columns in the grid
n_rows = (len(image_files) + n_cols - 1) // n_cols  # Calculate number of rows needed

fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))

# Flatten axes for easy iteration (handles case when there's only one row/column)
axes = axes.flatten()

for idx, image_file in enumerate(image_files):
    image_path = os.path.join(output_folder, image_file)

    # Open and display the image
    img = Image.open(image_path)
    axes[idx].imshow(img)
    axes[idx].axis('off')  # Turn off axes for a cleaner look
    axes[idx].set_title(image_file.split('.')[0], fontsize=12)  # Set the title as the file name (YearMonth)

# Hide unused subplots
for ax in axes[len(image_files):]:
    ax.axis('off')

# Adjust spacing between plots
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import os

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
output_folder = 'candlestick_patterns'  # Folder to save candlestick pattern images

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the CSV data
try:
    stock_data = pd.read_csv(csv_file_path)

    # Ensure required columns exist
    required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
    if not required_columns.issubset(stock_data.columns):
        raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

    # Convert 'Date' column to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    stock_data = stock_data.sort_values('Date')  # Sort data by date

    # Generate candlestick patterns for each day
    for _, row in stock_data.iterrows():
        date, open_price, high_price, low_price, close_price = row['Date'], row['Open'], row['High'], row['Low'], row['Close']

        # Initialize a figure and axis
        fig, ax = plt.subplots(figsize=(4, 6))  # Aspect ratio for candlestick pattern
        color = '#32CD32' if close_price >= open_price else '#FF4500'  # Green for bullish, red for bearish

        # Plot the candlestick body
        ax.bar(0, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.6, edgecolor='black', linewidth=1.5)

        # Plot the wicks
        ax.vlines(0, low_price, high_price, color='black', linewidth=1.2)

        # Add text labels (optional)
        ax.text(0.1, high_price, 'High', fontsize=8, color='black')
        ax.text(0.1, low_price, 'Low', fontsize=8, color='black')
        if close_price >= open_price:
            ax.text(0.1, close_price, 'Close', fontsize=8, color='black')
            ax.text(0.1, open_price, 'Open', fontsize=8, color='black')
        else:
            ax.text(0.1, open_price, 'Open', fontsize=8, color='black')
            ax.text(0.1, close_price, 'Close', fontsize=8, color='black')

        # Adjust plot aesthetics
        ax.set_xlim(-1, 1)  # Set fixed x-limits to center the candlestick
        ax.set_ylim(low_price - (0.1 * low_price), high_price + (0.1 * high_price))  # Add margin to y-axis
        ax.axis('off')  # Hide axes
        ax.set_title(f"{'Bullish' if close_price >= open_price else 'Bearish'} Candle Stick", fontsize=10)

        # Save the figure
        image_path = os.path.join(output_folder, f"{date.strftime('%Y-%m-%d')}.png")
        plt.savefig(image_path, bbox_inches='tight', pad_inches=0.3)
        plt.close(fig)  # Close the figure to free memory

    print(f"Candlestick patterns successfully saved in the '{output_folder}' folder.")

except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

import matplotlib.pyplot as plt
import os
from PIL import Image

# Define the folder containing candlestick pattern images
output_folder = 'candlestick_patterns'

# Get a list of all image files in the folder
image_files = [file for file in os.listdir(output_folder) if file.endswith('.png')]

# Sort the images by name (useful if filenames represent dates)
image_files.sort()

# Parameters for batching
batch_size = 20  # Number of images per figure
n_cols = 4  # Number of columns in the grid
n_rows = batch_size // n_cols  # Number of rows per grid

# Loop through images in batches
for i in range(0, len(image_files), batch_size):
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))

    # Flatten axes for easy iteration
    axes = axes.flatten()

    # Get the current batch of image files
    batch_files = image_files[i:i + batch_size]

    for idx, image_file in enumerate(batch_files):
        image_path = os.path.join(output_folder, image_file)

        # Open and display the image
        img = Image.open(image_path)
        axes[idx].imshow(img)
        axes[idx].axis('off')  # Turn off axes for a cleaner look
        axes[idx].set_title(image_file.split('.')[0], fontsize=8)  # Set the title as the file name

    # Hide unused subplots
    for ax in axes[len(batch_files):]:
        ax.axis('off')

    # Adjust spacing and show the batch
    plt.tight_layout()
    plt.show()

import pandas as pd
import os
import matplotlib.pyplot as plt

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
patterns_folder = 'candlestick_patterns'  # Folder with candlestick images

# Load stock data
stock_data = pd.read_csv(csv_file_path)

# Ensure required columns exist
required_columns = {'Date', 'Open', 'High', 'Low', 'Close', 'Volume'}
if not required_columns.issubset(stock_data.columns):
    raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

# Convert 'Date' column to datetime and sort
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Extract candlestick patterns from filenames
pattern_files = [file for file in os.listdir(patterns_folder) if file.endswith('.png')]
pattern_data = []

for file in pattern_files:
    # Extract date and type of pattern
    file_date = file.split('.')[0]  # Assuming 'YYYY-MM-DD.png' format
    file_date = pd.to_datetime(file_date)
    pattern_type = 'Bullish' if 'Bullish' in file else 'Bearish'
    pattern_data.append({'Date': file_date, 'Pattern': pattern_type})

# Convert pattern data into a DataFrame
patterns_df = pd.DataFrame(pattern_data)

# Merge patterns with stock data
merged_data = pd.merge(stock_data, patterns_df, on='Date', how='inner')

# Analyze price movement after candlestick patterns
merged_data['Next_Day_Close'] = merged_data['Close'].shift(-1)
merged_data['Price_Change_Percentage'] = ((merged_data['Next_Day_Close'] - merged_data['Close']) / merged_data['Close']) * 100

# Add trading volume and market movement analysis
merged_data['Volume_Change'] = merged_data['Volume'].pct_change()  # Volume percentage change
merged_data['High_Low_Spread'] = ((merged_data['High'] - merged_data['Low']) / merged_data['Low']) * 100  # Spread as % of low price

# Group by pattern and calculate average metrics
pattern_analysis = merged_data.groupby('Pattern').agg({
    'Price_Change_Percentage': 'mean',
    'Volume_Change': 'mean',
    'High_Low_Spread': 'mean'
})

# Visualization of Pattern Impact
pattern_analysis['Price_Change_Percentage'].plot(kind='bar', color=['green', 'red'], figsize=(8, 5))
plt.title('Average Next-Day Price Change by Candlestick Pattern')
plt.ylabel('Average Price Change (%)')
plt.xlabel('Candlestick Pattern')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.show()

# Summary of analysis
print("\nCandlestick Pattern Analysis:")
print(pattern_analysis)

import pandas as pd
import os
import matplotlib.pyplot as plt

# Define paths
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
patterns_folder = 'candlestick_patterns'  # Folder with candlestick images

# Load stock data
stock_data = pd.read_csv(csv_file_path)

# Ensure required columns exist
required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
if not required_columns.issubset(stock_data.columns):
    raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

# Convert 'Date' column to datetime and sort
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Extract candlestick patterns from filenames
pattern_files = [file for file in os.listdir(patterns_folder) if file.endswith('.png')]
pattern_data = []

for file in pattern_files:
    # Extract date and type of pattern (bullish/bearish)
    file_date = file.split('.')[0]  # Assuming the filename is in 'YYYY-MM-DD.png' format
    file_date = pd.to_datetime(file_date)  # Convert to datetime
    pattern_type = 'Bullish' if 'Bullish' in file else 'Bearish'  # Check pattern type in filename

    # Append extracted data
    pattern_data.append({'Date': file_date, 'Pattern': pattern_type})

# Convert pattern data into a DataFrame
patterns_df = pd.DataFrame(pattern_data)

# Merge patterns with stock data
merged_data = pd.merge(stock_data, patterns_df, on='Date', how='inner')

# Analyze price movement after candlestick patterns
merged_data['Next_Day_Close'] = merged_data['Close'].shift(-1)  # Close price of the next day
merged_data['Price_Change_Percentage'] = ((merged_data['Next_Day_Close'] - merged_data['Close']) / merged_data['Close']) * 100

# Add explainability
def explain_pattern(row):
    if row['Pattern'] == 'Bullish':
        return ("This pattern is classified as bullish because the price movement indicates that buyers "
                "have overtaken sellers, potentially reversing the downtrend or continuing an uptrend.")
    elif row['Pattern'] == 'Bearish':
        return ("This pattern is classified as bearish because the price movement shows that sellers "
                "have overpowered buyers, signaling a possible reversal of the uptrend or continuation of a downtrend.")

merged_data['Explanation'] = merged_data.apply(explain_pattern, axis=1)

# Display pattern explanation
for index, row in merged_data.iterrows():
    print(f"Date: {row['Date'].strftime('%Y-%m-%d')}")
    print(f"Pattern: {row['Pattern']}")
    print(f"Price Change (%): {row['Price_Change_Percentage']:.2f}")
    print(f"Explanation: {row['Explanation']}")
    print("-" * 80)

# Visualization of Pattern Impact
pattern_analysis = merged_data.groupby('Pattern')['Price_Change_Percentage'].mean()

plt.figure(figsize=(8, 5))
pattern_analysis.plot(kind='bar', color=['green', 'red'])
plt.title('Average Next-Day Price Change by Candlestick Pattern')
plt.ylabel('Average Price Change (%)')
plt.xlabel('Candlestick Pattern')
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.show()

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img
import os

# Parameters
image_folder_path = 'candlestick_images'  # Folder where images are extracted
num_images_to_display = 10  # Number of images to display

# Get list of image files in the folder
image_files = sorted([f for f in os.listdir(image_folder_path) if f.endswith('.png')])

# Display a few candlestick images
plt.figure(figsize=(10, 10))
for i, image_file in enumerate(image_files[:num_images_to_display]):
    img_path = os.path.join(image_folder_path, image_file)
    img = load_img(img_path, color_mode='grayscale')

    plt.subplot(2, 5, i + 1)  # Display in a 2x5 grid for 10 images
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.title(image_file)

plt.tight_layout()
plt.show()

import os
import pandas as pd
import matplotlib.pyplot as plt

# Define the CSV file path and check for required columns for candlestick chart
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
required_columns = {'Date', 'Open', 'High', 'Low', 'Close'}
if not required_columns.issubset(stock_data.columns):
    raise ValueError(f"The CSV file must contain these columns: {', '.join(required_columns)}")

# Convert Date column to datetime and sort by date
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data.sort_values('Date')

# Loop through each row to plot and display candlestick images
for _, row in stock_data.iterrows():
    date = row['Date']
    open_price = row['Open']
    high_price = row['High']
    low_price = row['Low']
    close_price = row['Close']

    # Determine if the movement is up or down and set color
    movement = "Up" if close_price >= open_price else "Down"
    color = 'green' if movement == "Up" else 'red'

    # Initialize a figure and axis
    fig, ax = plt.subplots(figsize=(4, 6))  # Adjust size for better visibility

    # Plot the candlestick body
    ax.bar(date, abs(close_price - open_price), bottom=min(open_price, close_price), color=color, width=0.4)

    # Plot high and low wicks
    ax.vlines(date, low_price, high_price, color='black', linewidth=0.6)

    # Add labels for open and close prices
    ax.text(date, open_price, f'Open: {open_price}', ha='center', va='bottom', color='blue', fontsize=8)
    ax.text(date, close_price, f'Close: {close_price}', ha='center', va='top', color='purple', fontsize=8)

    # Add movement label
    ax.text(date, high_price + (0.05 * high_price), movement, ha='center', color=color, fontsize=10, weight='bold')

    # Add the date label below the candlestick
    ax.text(date, low_price - (0.1 * low_price), date.strftime('%Y-%m-%d'), ha='center', va='top', fontsize=9, color='black')

    # Set plot limits and aesthetics
    ax.set_xlim(date - pd.Timedelta(days=0.5), date + pd.Timedelta(days=0.5))
    ax.set_ylim(low_price - (0.2 * low_price), high_price + (0.1 * high_price))
    ax.axis('off')  # Hide axes for a cleaner look

    # Show the plot
    plt.show()

import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import pandas as pd

# Parameters
image_folder_path = 'candlestick_images'
csv_file_path = 'ADANIPORTS.csv'
image_size = (64, 64)

# Load stock data
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']].sort_values('Date')

# Calculate "Up" or "Down" labels based on the stock price movement
stock_data['Movement'] = stock_data['Close'].diff().apply(lambda x: 'Up' if x > 0 else 'Down')

# Display images with labels
def display_images_with_labels(image_folder, stock_data, num_images=10):
    # Sort dates to match the image order
    stock_data = stock_data.sort_values('Date')
    displayed = 0

    for index, row in stock_data.iterrows():
        date_str = row['Date'].strftime('%Y%m%d')
        image_path = os.path.join(image_folder, f"candlestick_{date_str}.png")
        label = row['Movement']

        if os.path.exists(image_path) and displayed < num_images:
            img = load_img(image_path, target_size=image_size, color_mode='grayscale')
            plt.imshow(img, cmap='gray')
            plt.title(f"Date: {row['Date'].strftime('%Y-%m-%d')} - Movement: {label}")
            plt.axis('off')
            plt.show()

            displayed += 1

# Display the first 10 images with their labels
display_images_with_labels(image_folder_path, stock_data, num_images=10)

import os
import shutil

# Define the source and destination paths
source_folder = 'candlestick_images'  # Folder where your current candlestick images are stored
destination_folder = 'organized_candlestick_images'  # New folder to store organized images

# Create the new directory if it doesn't exist
os.makedirs(destination_folder, exist_ok=True)

# List all files in the source directory
for filename in os.listdir(source_folder):
    if filename.endswith('.png'):  # Check for PNG images (you can modify this if needed)
        # Construct full file path
        source_file = os.path.join(source_folder, filename)
        destination_file = os.path.join(destination_folder, filename)

        # Copy the image to the new directory
        shutil.copy(source_file, destination_file)
        print(f"Copied: {filename} to {destination_folder}")

print("All candlestick images have been organized.")

# Import the necessary libraries (if not already imported)
from tensorflow import keras

# ... (your code to create or load the model) ...

# 1. Create a new model (example)
model = keras.Sequential([
    # Add your layers here
    # For example:
    # keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    # keras.layers.Dense(10, activation='softmax')
])

# 2. Or, load a pre-trained model
# model = keras.models.load_model('path/to/your/pretrained/model.h5')

# After training or loading your model
model.save('model.h5')  # Save the model to a file named model.h5

import pandas as pd

# Load the stock data from CSV
csv_file_path = 'ADANIPORTS.csv'  # Replace with the actual path to your CSV file
stock_data = pd.read_csv(csv_file_path)

# Convert the 'Date' column to datetime format
stock_data['Date'] = pd.to_datetime(stock_data['Date'])

# Filter the data for April 30, 2021
april_30_data = stock_data[stock_data['Date'] == '2021-04-30']

# Check if data for April 30, 2021, is available
if not april_30_data.empty:
    # Get the closing price for April 30, 2021
    april_30_price = april_30_data['Close'].values[0]
    print(f"Stock price on April 30, 2021: ${april_30_price:.2f}")
else:
    print("No data available for April 30, 2021.")

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns

# Sort by date
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the test set (to evaluate model)
predictions = model.predict(X_test)

# Inverse scaling to get the predicted price back to original scale
predictions = scaler_y.inverse_transform(predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# Print predictions for May 1, 2021 (last date)
predicted_price = predictions[-1][0]
print(f"Predicted stock price for May 1, 2021: ${predicted_price:.2f}")

# Plot predictions vs actual values
plt.figure(figsize=(10,6))
plt.plot(y_test_actual, label='Actual Price')
plt.plot(predictions, label='Predicted Price')
plt.legend()
plt.show()

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, TimeDistributed
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
lstm_model.fit(X_train, y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
lstm_predictions = lstm_model.predict(X_test)
lstm_predictions = scaler_y.inverse_transform(lstm_predictions)

# Build the CNN-LSTM model using the same stock price input
# Reshape X for CNN-LSTM input: add a new axis for channels
X_cnn_lstm = X.reshape((X.shape[0], X.shape[1], 1, 1))  # (samples, time steps, height, width)

# Build the CNN-LSTM model
cnn_lstm_model = Sequential([
    TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),  # Only prices
    TimeDistributed(MaxPooling2D((1, 1))),
    TimeDistributed(Flatten()),
    LSTM(50, return_sequences=False),
    Dense(1)
])

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN-LSTM model
cnn_lstm_model.fit(X_cnn_lstm[:train_size], y_train, epochs=20, batch_size=32)

# Make predictions for the last day in the test set
cnn_lstm_predictions = cnn_lstm_model.predict(X_cnn_lstm[train_size:])
cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)

# Compare predictions
predicted_price_lstm = lstm_predictions[-1][0]
predicted_price_cnn_lstm = cnn_lstm_predictions[-1][0]

print(f"Predicted stock price (LSTM) for May 1, 2021: ${predicted_price_lstm:.2f}")
print(f"Predicted stock price (CNN-LSTM) for May 1, 2021: ${predicted_price_cnn_lstm:.2f}")

# Plot predictions vs actual values
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Actual Price', color='blue')
plt.plot(lstm_predictions, label='LSTM Predicted Price', color='red')
plt.plot(cnn_lstm_predictions, label='CNN-LSTM Predicted Price', color='green')
plt.legend()
plt.title('Stock Price Prediction')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.show()

import os
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, TimeDistributed
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_percentage_error
import matplotlib.pyplot as plt

# Load stock data
csv_file_path = 'ADANIPORTS.csv'  # Path to your stock data CSV
stock_data = pd.read_csv(csv_file_path)
stock_data['Date'] = pd.to_datetime(stock_data['Date'])
stock_data = stock_data[['Date', 'Close']]  # Using Date and Close columns
stock_data = stock_data.sort_values('Date')

# Normalize the stock prices using MinMaxScaler
scaler_y = MinMaxScaler(feature_range=(0, 1))
stock_data['Close'] = scaler_y.fit_transform(stock_data[['Close']])

# Prepare the dataset: Use the last 10 days' stock prices to predict the next day
sequence_length = 10  # Use the last 10 days' stock prices to predict the next day
def prepare_data(stock_data, sequence_length):
    X = []
    y = []

    for i in range(len(stock_data) - sequence_length):
        X.append(stock_data['Close'].iloc[i:i + sequence_length].values)
        y.append(stock_data['Close'].iloc[i + sequence_length])  # The next day's price

    X = np.array(X)
    y = np.array(y)

    return X, y

# Prepare the data for training
X, y = prepare_data(stock_data, sequence_length)

# Reshape X for LSTM input
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, time steps, features)

# Split the data into training and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
lstm_model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(sequence_length, 1)),
    LSTM(50),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)

# Make predictions for the test set
lstm_predictions = lstm_model.predict(X_test)
lstm_predictions = scaler_y.inverse_transform(lstm_predictions)
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# Build the CNN-LSTM model using the same stock price input
# Reshape X for CNN-LSTM input: add a new axis for channels
X_cnn_lstm = X.reshape((X.shape[0], X.shape[1], 1, 1))  # (samples, time steps, height, width)

# Build the CNN-LSTM model
cnn_lstm_model = Sequential([
    TimeDistributed(Conv2D(32, (1, 1), activation='relu'), input_shape=(sequence_length, 1, 1, 1)),  # Only prices
    TimeDistributed(MaxPooling2D((1, 1))),
    TimeDistributed(Flatten()),
    LSTM(50, return_sequences=False),
    Dense(1)
])

cnn_lstm_model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN-LSTM model
cnn_lstm_model.fit(X_cnn_lstm[:train_size], y_train, epochs=20, batch_size=32, verbose=0)

# Make predictions for the test set
cnn_lstm_predictions = cnn_lstm_model.predict(X_cnn_lstm[train_size:])
cnn_lstm_predictions = scaler_y.inverse_transform(cnn_lstm_predictions)

# Calculate Mean Absolute Percentage Error (MAPE) for both models
lstm_mape = mean_absolute_percentage_error(y_test_actual, lstm_predictions) * 100
cnn_lstm_mape = mean_absolute_percentage_error(y_test_actual, cnn_lstm_predictions) * 100

print(f"LSTM Model MAPE: {lstm_mape:.2f}%")
print(f"CNN-LSTM Model MAPE: {cnn_lstm_mape:.2f}%")

# Calculate the difference between the LSTM and CNN-LSTM predicted prices
price_difference = np.abs(lstm_predictions - cnn_lstm_predictions)

# Calculate Mean Absolute Error (MAE) for the difference
mae_difference = np.mean(price_difference)
print(f"Mean Absolute Error between LSTM and CNN-LSTM predictions: {mae_difference:.4f}")

# Plot the stock prices for both models and the difference
plt.figure(figsize=(12, 6))

# Plot Actual vs LSTM predicted prices
plt.subplot(2, 1, 1)
plt.plot(y_test_actual, label='Actual Price', color='blue')
plt.plot(lstm_predictions, label='LSTM Predicted Price', color='red', linestyle='dashed')
plt.plot(cnn_lstm_predictions, label='CNN-LSTM Predicted Price', color='green', linestyle='dotted')
plt.legend()
plt.title('Stock Price Prediction Comparison (LSTM vs CNN-LSTM)')
plt.xlabel('Days')
plt.ylabel('Stock Price')

# Plot the difference between LSTM and CNN-LSTM predictions
plt.subplot(2, 1, 2)
plt.plot(price_difference, label='Price Difference (LSTM vs CNN-LSTM)', color='purple')
plt.legend()
plt.title('Difference in Predicted Prices (LSTM vs CNN-LSTM)')
plt.xlabel('Days')
plt.ylabel('Price Difference')

plt.tight_layout()
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Make predictions on the test set
y_pred = hybrid_model.predict([X_test_price, X_test_images])

# Inverse transform predictions and actual values to original scale
y_pred_rescaled = scaler_y.inverse_transform(y_pred)
y_test_rescaled = scaler_y.inverse_transform(y_test_images.reshape(-1, 1))

# Calculate regression metrics
mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_rescaled, y_pred_rescaled)

# Print the results
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"RÂ² Score: {r2:.2f}")